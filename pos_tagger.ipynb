{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pos_tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SwpQHaxGU4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.metrics import classification_report\n",
        "from data_preparation.converter_from_ud_to_txt import UDConverter\n",
        "from train.train_pipeline import train_eval_loop, predict_with_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6E8QCAFnHrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "5d68b08b-3bb2-4927-f8ad-77c9ec532b4c"
      },
      "source": [
        "!git clone https://github.com/IlyaSk10/POS_Tagger_with_using_CNN/\n",
        "%cd POS_Tagger_with_using_CNN\n",
        "!unzip SYNTAGRUS_texts.zip\n",
        "!head syntagrus_full.ud\n",
        "\n",
        "UDConverter.convert_from_conllu(\"syntagrus_full.ud\", \"syntagrus_fixed.txt\")\n",
        "!head syntagrus_fixed.txt\n",
        "text_data= \"syntagrus_fixed.txt\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'POS_Tagger_with_using_CNN'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 43 (delta 16), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n",
            "/content/POS_Tagger_with_using_CNN\n",
            "Archive:  SYNTAGRUS_texts.zip\n",
            "  inflating: syntagrus_full.ud       \n",
            "1\tНачальник\tначальник\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "2\tобластного\tобластной\tADJ\tCase=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "3\tуправления\tуправление\tNOUN\tAnimacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "4\tсвязи\tсвязь\tNOUN\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "5\tСемен\tсемен\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "6\tЕремеевич\tеремеевич\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "7\tбыл\tбыть\tVERB\tGender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "8\tчеловек\tчеловек\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "9\tпростой\tпростой\tADJ\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "10\t,\t,\tPUNCT\t_\n",
            "Начальник\tначальник\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "областного\tобластной\tADJ\tCase=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "управления\tуправление\tNOUN\tCase=Gen|Gender=Neut|Number=Sing\n",
            "связи\tсвязь\tNOUN\tCase=Gen|Gender=Fem|Number=Sing\n",
            "Семен\tсемен\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "Еремеевич\tеремеевич\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "был\tбыть\tVERB\tGender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "человек\tчеловек\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "простой\tпростой\tADJ\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            ",\t,\tPUNCT\t_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXixbTRwJ2fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_from_file(file):\n",
        "  with open(file,'r',encoding='utf-8') as f:\n",
        "    read_file=f.read().split('\\n')\n",
        "  return read_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0fUZwDlQ48z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=load_from_file(text_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-2_W2EJhmR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a558423f-401a-4027-f76e-24ccbd09c3d0"
      },
      "source": [
        "import string\n",
        "dataset = list(filter(None, dataset))\n",
        "text = ''.join([('' if iteration.split('\\t')[2]=='PUNCT' else ' ')+iteration.split('\\t')[0] for iteration in dataset[:200]]).strip()\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начальник областного управления связи Семен Еремеевич был человек простой, приходил на работу всегда вовремя, здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом\" Муха\". В приемной его с утра ожидали посетители,- кое-кто с важными делами, а кое-кто и с такими, которые легко можно было решить в нижестоящих инстанциях, не затрудняя Семена Еремеевича. Однако стиль работы Семена Еремеевича заключался в том, чтобы принимать всех желающих и лично вникать в дело. Приемная была обставлена просто, но по-деловому. У двери стоял стол секретарши, на столе- пишущая машинка с широкой кареткой. В углу висел репродуктор и играло радио для развлечения ожидающих и еще для того, чтобы заглушать голос начальника, доносившийся из кабинета, так_как, бесспорно, среди посетителей могли находиться и случайные люди. Кабинет отличался скромностью, присущей Семену Еремеевичу. В глубине стоял широкий письменный стол с бронзовыми чернильницами и перед ним два кожаных кресла. Справа был стол для заседаний- длинный, накрытый зеленым сукном и с обеих сторон аккуратно заставленный стульями. Семен Еремеевич очень не любил, когда за этот стол кто-нибудь\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez72JAgsijVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_text (dataset):\n",
        "  clean_dataset=[]\n",
        "  for sentence in dataset:\n",
        "    if sentence.split('\\t')[0]!='.' and sentence.split('\\t')[2]!='PUNCT':\n",
        "      clean_dataset.append([sentence.split('\\t')[0].lower(),sentence.split('\\t')[2]])\n",
        "    elif sentence.split('\\t')[0]=='.':\n",
        "      clean_dataset.append([sentence.split('\\t')[0].lower(),sentence.split('\\t')[2]])\n",
        "    else:\n",
        "      continue\n",
        "  return clean_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phwj_XPyrOpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_dataset=clear_text(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5pZulejsDmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "90872825-4544-4ca0-b08a-f21f704056f6"
      },
      "source": [
        "print(clean_dataset[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['начальник', 'NOUN'], ['областного', 'ADJ'], ['управления', 'NOUN'], ['связи', 'NOUN'], ['семен', 'NOUN'], ['еремеевич', 'NOUN'], ['был', 'VERB'], ['человек', 'NOUN'], ['простой', 'ADJ'], ['приходил', 'VERB'], ['на', 'ADP'], ['работу', 'NOUN'], ['всегда', 'ADV'], ['вовремя', 'ADV'], ['здоровался', 'VERB'], ['с', 'ADP'], ['секретаршей', 'NOUN'], ['за', 'ADP'], ['руку', 'NOUN'], ['и', 'CONJ']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpXoCZ8a6Hze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concatenate_words(dataset):\n",
        "  concat_words=[]\n",
        "  concat_labels=[]\n",
        "  sentence=[]\n",
        "  labels=[]\n",
        "  for word in dataset:\n",
        "    if word[1]!='PUNCT':\n",
        "      sentence.append(word[0])\n",
        "      labels.append(word[1])\n",
        "    else:\n",
        "      concat_words.append([word for word in sentence])\n",
        "      concat_labels.append([label for label in labels])\n",
        "      sentence.clear()\n",
        "      labels.clear()\n",
        "  return concat_words,concat_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cojUqfC0901R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text,labels_sen=concatenate_words(clean_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbVxmVRQwKSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2e6dadb1-e4f2-412e-8bf2-95b94ad49339"
      },
      "source": [
        "clean_dataset=[line for line in clean_dataset if line!='']\n",
        "MAX_LEN_TOKEN=max(len(line[0]) for line in clean_dataset)\n",
        "NUMBER_UNIQUE_TOKEN=len(set(line[0] for line in clean_dataset if line[1]!='PUNCT'))\n",
        "MAX_LEN_SENTENCE=max(len(sentence) for sentence in text)\n",
        "print('Максимальная длина токена', MAX_LEN_TOKEN)\n",
        "print('Количество уникальных токенов' , NUMBER_UNIQUE_TOKEN)\n",
        "print('Максимальная длина предложения' , MAX_LEN_SENTENCE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Максимальная длина токена 31\n",
            "Количество уникальных токенов 104251\n",
            "Максимальная длина предложения 216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzin5II3qdmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7e61188-0bfa-41a7-f5d3-1efd4a14edd9"
      },
      "source": [
        "labels = ['<NOTAG>'] + sorted({token[1] for token in clean_dataset})\n",
        "label2id = {label: i+1 for i, label in enumerate(labels)}\n",
        "print('Метки частей речи' , label2id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метки частей речи {'<NOTAG>': 1, 'ADJ': 2, 'ADP': 3, 'ADV': 4, 'CONJ': 5, 'DET': 6, 'H': 7, 'INTJ': 8, 'NOUN': 9, 'NUM': 10, 'PART': 11, 'PRON': 12, 'PUNCT': 13, 'VERB': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hov349dzJsYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_vocab(text,pad_symbol='<PAD>'):\n",
        "  sentence=' '.join(line[0].lower() for line in text)\n",
        "  mydict = dict((j, i+1) for i, j in enumerate(set(sentence)))\n",
        "  mydict.update({pad_symbol:max(mydict.values())+1})\n",
        "  return mydict\n",
        "\n",
        "def counter(dataset,most_freq_symbols):\n",
        "  if most_freq_symbols is None:\n",
        "    most_freq_symbols=5\n",
        "  sentence=' '.join([word[0] for word in dataset])\n",
        "  return Counter(list(sentence)).most_common(most_freq_symbols)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eht7psJXXKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1155a96f-4960-43a9-9f36-06f8baa50479"
      },
      "source": [
        "print('Символы словаря',build_vocab(text=clean_dataset[:10]),'\\n','Наиболее частотные символы',counter(clean_dataset[:10],most_freq_symbols=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Символы словаря {'й': 1, 'м': 2, 'н': 3, 'д': 4, 'я': 5, 'б': 6, 'т': 7, 'ч': 8, 'к': 9, 'л': 10, 'в': 11, 'а': 12, ' ': 13, 'з': 14, 'ь': 15, 'с': 16, 'х': 17, 'ы': 18, 'о': 19, 'е': 20, 'п': 21, 'у': 22, 'р': 23, 'г': 24, 'и': 25, '<PAD>': 26} \n",
            " Наиболее частотные символы [(' ', 9), ('е', 9), ('о', 7), ('л', 6), ('и', 6), ('н', 5), ('а', 4), ('с', 4), ('р', 4), ('в', 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7pcJDs1eNIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=build_vocab(text=clean_dataset)\n",
        "\n",
        "A=np.zeros(shape=(len(text[:40000]),MAX_LEN_SENTENCE,MAX_LEN_TOKEN))\n",
        "B=np.zeros(shape=(len(text[:40000]),MAX_LEN_SENTENCE))\n",
        "for i in range(len(text[:40000])):\n",
        "  for j,word in enumerate(text[i]):\n",
        "    conv=[number for letter in word for symbol,number in vocab.items() if letter==symbol]\n",
        "    conv1=[number for symbol,number in label2id.items() if labels_sen[i][j]==symbol]\n",
        "    np.put(A[i,j],[k for k in range(len(word))],conv)\n",
        "    np.put(B[i],j,conv1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtugO1kJT4Rw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5c8a65ea-40a7-49e8-df9a-ded247e9f765"
      },
      "source": [
        "A[1][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [69., 79., 83., 64.,  3.,  5., 63.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [64., 82., 63.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [56.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [73., 15., 79., 30.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqt8TAV3UQs2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "604bb1bc-e9bc-4554-9a74-4b020232650b"
      },
      "source": [
        "B[1][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  9., 12.,  3.,  9.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGOyaw7gULCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_pad(words2id,text,pad_symbol,max_len_token,add_boundary=True):\n",
        "  mat_with_boundary=np.zeros(shape=(len(text),MAX_LEN_SENTENCE,MAX_LEN_TOKEN+1),dtype=int)\n",
        "  for i in range(len(text)):\n",
        "    for j in range(len(text[i])):\n",
        "      if add_boundary==True:\n",
        "        mat_with_boundary[i,j]=np.insert(words2id[i,j],0,pad_symbol)\n",
        "      else:\n",
        "        continue\n",
        "  return words2id if (add_boundary==False) else mat_with_boundary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-7nlU7CWXrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A=add_pad(A,text[:40000],pad_symbol=0,max_len_token=MAX_LEN_TOKEN,add_boundary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky2aAKB4_3OK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0a82f616-d4b0-4a4a-caf3-624a07ab0a66"
      },
      "source": [
        "A[1,:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 29,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 69, 79, 83, 64,  3,  5, 63,  2,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 64, 82, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 56,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 73, 15, 79, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 63, 70, 83,  7, 30, 27, 83,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 69, 63, 56, 64, 15, 83, 15, 64, 27, 83,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 24, 63, 64, 50, 24, 15, 63,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 56,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 29, 30, 70,  5, 61,  3, 83,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1722F-J2AYcp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "757480e1-50b5-4a6f-efa2-f7e89eae0b9b"
      },
      "source": [
        "B[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  9., 12.,  3.,  9., 14.,  9., 12.,  3.,  2.,  9.,  5., 12.,\n",
              "       11.,  3.,  6.,  6.,  4.,  4., 14., 14.,  3.,  2.,  9., 11., 14.,\n",
              "        9.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s99eLc4cvIRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e263305-c40f-4006-bf1d-34be99237fcf"
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(A, B, test_size=0.33, random_state=42)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cat=to_categorical(y_train, num_classes=len(label2id.values())+1)\n",
        "y_test_cat=to_categorical(y_test, num_classes=len(label2id.values())+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y6BDTOQDxeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class StackedConv1d(nn.Module):\n",
        "  def __init__(self,features_num,layers_n=1,kernel_size=3,conv_layer=nn.Conv1d,dropout=0.0):\n",
        "    super().__init__()\n",
        "    layers=[]\n",
        "    for _ in range(layers_n):\n",
        "      layers.append(nn.Sequential(conv_layer(features_num,features_num,kernel_size,padding=kernel_size//2),\n",
        "                                  nn.Dropout(dropout),\n",
        "                                  nn.LeakyReLU()))\n",
        "      self.layers=nn.ModuleList(layers)\n",
        "\n",
        "  # simple ResNet\n",
        "  def forward(self,x):\n",
        "    for layer in self.layers:\n",
        "      x=x+layer(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pCQhh1WVA9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SingleTokenPOSTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n",
        "        super().__init__()\n",
        "        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.backbone = StackedConv1d(embedding_size, **kwargs)\n",
        "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.out = nn.Linear(embedding_size, labels_num)\n",
        "        self.labels_num = labels_num\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n",
        "        batch_size, max_sent_len, max_token_len = tokens.shape\n",
        "        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n",
        "        \n",
        "        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n",
        "        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n",
        "        \n",
        "        features = self.backbone(char_embeddings)\n",
        "        \n",
        "        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n",
        "        \n",
        "        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n",
        "        logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n",
        "        logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CcmId44JNRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d5c34cc-be0f-4711-8083-70f24e62009b"
      },
      "source": [
        "single_token_model=SingleTokenPOSTagger(len(vocab),len(label2id),embedding_size=64,layers_n=3,kernel_size=3,dropout=0.3)\n",
        "print(\"Количество параметров\", sum(np.product(t.shape) for t in single_token_model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество параметров 43342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4MemvZXd9GS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=torch.from_numpy(X_train).type(torch.LongTensor)\n",
        "y_train=torch.from_numpy(y_train).type(torch.LongTensor)\n",
        "X_test=torch.from_numpy(X_test).type(torch.LongTensor)\n",
        "y_test=torch.from_numpy(y_test).type(torch.LongTensor)\n",
        "\n",
        "train_dataset=TensorDataset(X_train,y_train)\n",
        "test_dataset=TensorDataset(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.319470Z",
          "start_time": "2019-10-29T19:46:25.552Z"
        },
        "scrolled": false,
        "id": "KoCMCl7MJ6fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "72165e79-6b4e-47e5-a095-1685825534b2"
      },
      "source": [
        "(best_val_loss,\n",
        " best_single_token_model) = train_eval_loop(single_token_model,\n",
        "                                            train_dataset,\n",
        "                                            test_dataset,\n",
        "                                            F.cross_entropy,\n",
        "                                            lr=5e-3,\n",
        "                                            epoch_n=10,\n",
        "                                            batch_size=64,\n",
        "                                            device='cuda',\n",
        "                                            early_stopping_patience=5,\n",
        "                                            max_batches_per_epoch_train=500,\n",
        "                                            max_batches_per_epoch_val=100,\n",
        "                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                       factor=0.5,\n",
        "                                                                                                                       verbose=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпоха 0\n",
            "Эпоха: 501 итераций, 282.44 сек\n",
            "Среднее значение функции потерь на обучении 0.08025922445197424\n",
            "Среднее значение функции потерь на валидации 0.036914107103896615\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 1\n",
            "Эпоха: 501 итераций, 282.22 сек\n",
            "Среднее значение функции потерь на обучении 0.028614820871583953\n",
            "Среднее значение функции потерь на валидации 0.02822994330141804\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 2\n",
            "Эпоха: 501 итераций, 282.23 сек\n",
            "Среднее значение функции потерь на обучении 0.02423277378320218\n",
            "Среднее значение функции потерь на валидации 0.026719287074733488\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 3\n",
            "Эпоха: 501 итераций, 282.22 сек\n",
            "Среднее значение функции потерь на обучении 0.022381869048073502\n",
            "Среднее значение функции потерь на валидации 0.022604787897429254\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 4\n",
            "Эпоха: 501 итераций, 282.22 сек\n",
            "Среднее значение функции потерь на обучении 0.02125430090014568\n",
            "Среднее значение функции потерь на валидации 0.02318061840268645\n",
            "\n",
            "Эпоха 5\n",
            "Эпоха: 501 итераций, 282.22 сек\n",
            "Среднее значение функции потерь на обучении 0.020393513594781924\n",
            "Среднее значение функции потерь на валидации 0.02226567166018309\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 6\n",
            "Эпоха: 501 итераций, 282.23 сек\n",
            "Среднее значение функции потерь на обучении 0.019927750772865353\n",
            "Среднее значение функции потерь на валидации 0.02669444126952993\n",
            "\n",
            "Эпоха 7\n",
            "Эпоха: 501 итераций, 282.22 сек\n",
            "Среднее значение функции потерь на обучении 0.019403903687488056\n",
            "Среднее значение функции потерь на валидации 0.022333966088619563\n",
            "\n",
            "Эпоха 8\n",
            "Эпоха: 501 итераций, 282.22 сек\n",
            "Среднее значение функции потерь на обучении 0.018868007223138552\n",
            "Среднее значение функции потерь на валидации 0.02179569941899269\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 9\n",
            "Эпоха: 501 итераций, 282.23 сек\n",
            "Среднее значение функции потерь на обучении 0.01859569804233586\n",
            "Среднее значение функции потерь на валидации 0.020432315397970746\n",
            "Новая лучшая модель!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y0jxUgA2Eqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(best_single_token_model.state_dict(), '/model/single_token_pos.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfutrQjE2JP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "single_token_model.load_state_dict(torch.load('/model/single_token_pos.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:47:48.324276Z",
          "start_time": "2019-10-29T19:46:48.445Z"
        },
        "id": "DOpWI2NoJ6f1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "8065e9d3-7a50-4bd8-9b3c-8cc3f830118c"
      },
      "source": [
        "test_pred = predict_with_model(single_token_model, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.tensor(test_pred),\n",
        "                            torch.tensor(y_test_cat))\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/205.75 [00:03<00:00, 57.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на валидации 0.020207911729812622\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <NOTAG>       1.00      1.00      1.00   1231232\n",
            "         ADJ       0.84      0.94      0.89     11222\n",
            "         ADP       1.00      0.99      0.99     10585\n",
            "         ADV       0.84      0.88      0.86      6165\n",
            "         AUX       0.87      0.63      0.73      1106\n",
            "       CCONJ       0.89      0.98      0.93      4410\n",
            "         DET       0.75      0.87      0.81      3085\n",
            "        INTJ       0.00      0.00      0.00        11\n",
            "        NOUN       0.98      0.91      0.94     27974\n",
            "         NUM       0.96      0.87      0.91      1829\n",
            "        PART       0.97      0.77      0.86      3877\n",
            "        PRON       0.94      0.78      0.85      5598\n",
            "       PROPN       0.77      0.95      0.85      4438\n",
            "       PUNCT       1.00      1.00      1.00     22694\n",
            "       SCONJ       0.77      0.74      0.75      2258\n",
            "         SYM       1.00      0.96      0.98        53\n",
            "        VERB       0.90      0.95      0.92     13078\n",
            "           X       0.97      0.73      0.84       105\n",
            "\n",
            "    accuracy                           0.99   1349720\n",
            "   macro avg       0.86      0.83      0.84   1349720\n",
            "weighted avg       0.99      0.99      0.99   1349720\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}