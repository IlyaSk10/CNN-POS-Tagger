{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6E8QCAFnHrv",
        "colab_type": "code",
        "outputId": "0b95ca61-7817-48b0-8a6e-b5778b8b3278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!git clone https://github.com/IlyaSk10/POS_Tagger_with_using_CNN/\n",
        "%cd POS_Tagger_with_using_CNN\n",
        "!unzip SYNTAGRUS_texts.zip\n",
        "!head syntagrus_full.ud\n",
        "from data_preparation.converter_from_ud_to_txt import UDConverter\n",
        "UDConverter.convert_from_conllu(\"syntagrus_full.ud\", \"syntagrus_fixed.txt\")\n",
        "!head syntagrus_fixed.txt\n",
        "text_data= \"syntagrus_fixed.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'POS_Tagger_with_using_CNN'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 31 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (31/31), done.\n",
            "/content/POS_Tagger_with_using_CNN\n",
            "Archive:  SYNTAGRUS_texts.zip\n",
            "  inflating: syntagrus_full.ud       \n",
            "1\tНачальник\tначальник\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "2\tобластного\tобластной\tADJ\tCase=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "3\tуправления\tуправление\tNOUN\tAnimacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "4\tсвязи\tсвязь\tNOUN\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "5\tСемен\tсемен\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "6\tЕремеевич\tеремеевич\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "7\tбыл\tбыть\tVERB\tGender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "8\tчеловек\tчеловек\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "9\tпростой\tпростой\tADJ\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "10\t,\t,\tPUNCT\t_\n",
            "Начальник\tначальник\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "областного\tобластной\tADJ\tCase=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "управления\tуправление\tNOUN\tCase=Gen|Gender=Neut|Number=Sing\n",
            "связи\tсвязь\tNOUN\tCase=Gen|Gender=Fem|Number=Sing\n",
            "Семен\tсемен\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "Еремеевич\tеремеевич\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "был\tбыть\tVERB\tGender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "человек\tчеловек\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "простой\tпростой\tADJ\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            ",\t,\tPUNCT\t_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXixbTRwJ2fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_from_file(file):\n",
        "  with open(file,'r',encoding='utf-8') as f:\n",
        "    c=f.read().split('\\n')\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0fUZwDlQ48z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=load_from_file(text_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbVxmVRQwKSc",
        "colab_type": "code",
        "outputId": "271dbb23-5e72-4891-b9c4-3378c5e92ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset=[line for line in dataset if line!='']\n",
        "MAX_LEN_TOKEN=max(len(line.split('\\t')[0]) for line in dataset)\n",
        "NUMBER_UNIQUE_TOKEN=len(set(line.split('\\t')[0] for line in dataset if line.split('\\t')[2]!='PUNCT'))\n",
        "print('Максимальная длина токена', MAX_LEN_TOKEN)\n",
        "print('Количество уникальных токенов' , NUMBER_UNIQUE_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Максимальная длина токена 31\n",
            "Количество уникальных токенов 112875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzin5II3qdmO",
        "colab_type": "code",
        "outputId": "9cfb81a3-821c-405d-f8a3-fef508c9d64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "labels = ['<NOTAG>'] + sorted({token.split('\\t')[2] for token in dataset})\n",
        "label2id = {label: i+1 for i, label in enumerate(labels)}\n",
        "print('Метки частей речи' , label2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метки частей речи {'<NOTAG>': 1, 'ADJ': 2, 'ADP': 3, 'ADV': 4, 'CONJ': 5, 'DET': 6, 'H': 7, 'INTJ': 8, 'NOUN': 9, 'NUM': 10, 'PART': 11, 'PRON': 12, 'PUNCT': 13, 'VERB': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hov349dzJsYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "def build_vocab(text,pad_symbol='<PAD>'):\n",
        "  sentence=' '.join(line.split('\\t')[0] for line in text)\n",
        "  mydict = dict((j, i+1) for i, j in enumerate(set(sentence)))\n",
        "  mydict.update({pad_symbol:max(mydict.values())+1})\n",
        "  return mydict\n",
        "\n",
        "def counter(dataset,most_freq_symbols):\n",
        "  if most_freq_symbols is None:\n",
        "    most_freq_symbols=5\n",
        "  sentence=' '.join([word.split('\\t')[0] for word in dataset])\n",
        "  return Counter(list(sentence)).most_common(most_freq_symbols)    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eht7psJXXKb",
        "colab_type": "code",
        "outputId": "6f484cef-723e-448d-b8b1-c6a0c97fb677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('Символы словаря',build_vocab(text=dataset[:10]),'\\n','Наиболее частотные символы',counter(dataset[:10],most_freq_symbols=10))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Символы словаря {'ы': 1, 'к': 2, 'л': 3, 'о': 4, 'а': 5, 'т': 6, 'й': 7, ',': 8, 'ь': 9, 'в': 10, 'ч': 11, 'я': 12, 'б': 13, 'е': 14, 'Н': 15, 'з': 16, 'п': 17, 'н': 18, 'С': 19, 'Е': 20, 'у': 21, 'г': 22, ' ': 23, 'р': 24, 'с': 25, 'м': 26, 'и': 27, '<PAD>': 28} \n",
            " Наиболее частотные символы [(' ', 9), ('е', 8), ('о', 6), ('л', 5), ('а', 4), ('н', 4), ('и', 4), ('в', 4), ('ч', 3), ('с', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XICFcquJRA4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=build_vocab(text=dataset[:10])\n",
        "\n",
        "word2id=[]\n",
        "label_to_id=[]\n",
        "for index in range(len(dataset)):\n",
        "  word2id.append([number for j in dataset[index].split('\\t')[0] for symbol,number in vocab.items() if symbol==j.lower()])\n",
        "  label_to_id.append([number for symbol,number in label2id.items() if symbol==dataset[index].split('\\t')[2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GagXmv0GKnOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad(word2id,pad_symbol,max_len_token):\n",
        "  mat_with_pads=np.zeros(shape=(len(word2id),MAX_LEN_TOKEN),dtype=int)\n",
        "  for index,ident in enumerate(word2id):\n",
        "    np.put(mat_with_pads[index],range(len(ident)),ident)\n",
        "  return mat_with_pads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wowB96-Ppfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words=pad(word2id,pad_symbol=0,max_len_token=MAX_LEN_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVRfLsHMnX5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "f750c98c-a72e-4921-f125-1a9749cc4078"
      },
      "source": [
        "print('Преобразование слов в набор симвлолов для {} слов'.format(10),'\\n',words[:10])\n",
        "print('Преобразование частей речи в метки для {} меток'.format(10),'\\n',label_to_id[:10])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Преобразование слов в набор симвлолов для 10 слов \n",
            " [[18  5 11  5  3  9 18 27  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 4 13  3  5 25  6 18  4 22  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [21 17 24  5 10  3 14 18 27 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [25 10 12 16 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [25 14 26 14 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [14 24 14 26 14 14 10 27 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [13  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [11 14  3  4 10 14  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [17 24  4 25  6  4  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]]\n",
            "Преобразование частей речи в метки для 10 меток \n",
            " [[9], [2], [9], [9], [9], [9], [14], [9], [2], [13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s99eLc4cvIRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e0291a8-705f-4fab-a9bc-7f938f4aba4c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(words, label_to_id, test_size=0.33, random_state=42)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cat=to_categorical(y_train, num_classes=len(labels)+1)\n",
        "y_test_cat=to_categorical(y_test, num_classes=len(labels)+1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC-m7FwS5684",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Embedding,Bidirectional,LSTM\n",
        "\n",
        "# создание сети\n",
        "model = Sequential()\n",
        "vocab_size=NUMBER_UNIQUE_TOKEN\n",
        "num_classes=len(labels)+1\n",
        "model.add(Embedding(vocab_size, output_dim= MAX_LEN_TOKEN, input_length=MAX_LEN_TOKEN))\n",
        "model.add(Bidirectional(LSTM(units=32, input_shape=(NUMBER_UNIQUE_TOKEN, MAX_LEN_TOKEN),dropout = 0.2)))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# обучение модели\n",
        "model.fit(X_train, y_train_cat, batch_size = 64,epochs=1,validation_data = (X_test, y_test_cat),verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}