{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pos_tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6E8QCAFnHrv",
        "colab_type": "code",
        "outputId": "768e54b0-e2d7-499f-8267-d080a682ae4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!git clone https://github.com/IlyaSk10/POS_Tagger_with_using_CNN/\n",
        "%cd POS_Tagger_with_using_CNN\n",
        "!unzip SYNTAGRUS_texts.zip\n",
        "!head syntagrus_full.ud\n",
        "from data_preparation.converter_from_ud_to_txt import UDConverter\n",
        "\n",
        "UDConverter.convert_from_conllu(\"syntagrus_full.ud\", \"syntagrus_fixed.txt\")\n",
        "!head syntagrus_fixed.txt\n",
        "text_data= \"syntagrus_fixed.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'POS_Tagger_with_using_CNN'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 39 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n",
            "/content/POS_Tagger_with_using_CNN\n",
            "Archive:  SYNTAGRUS_texts.zip\n",
            "  inflating: syntagrus_full.ud       \n",
            "1\tНачальник\tначальник\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "2\tобластного\tобластной\tADJ\tCase=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "3\tуправления\tуправление\tNOUN\tAnimacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "4\tсвязи\tсвязь\tNOUN\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "5\tСемен\tсемен\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "6\tЕремеевич\tеремеевич\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "7\tбыл\tбыть\tVERB\tGender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "8\tчеловек\tчеловек\tNOUN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "9\tпростой\tпростой\tADJ\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "10\t,\t,\tPUNCT\t_\n",
            "Начальник\tначальник\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "областного\tобластной\tADJ\tCase=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "управления\tуправление\tNOUN\tCase=Gen|Gender=Neut|Number=Sing\n",
            "связи\tсвязь\tNOUN\tCase=Gen|Gender=Fem|Number=Sing\n",
            "Семен\tсемен\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "Еремеевич\tеремеевич\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "был\tбыть\tVERB\tGender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "человек\tчеловек\tNOUN\tCase=Nom|Gender=Masc|Number=Sing\n",
            "простой\tпростой\tADJ\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            ",\t,\tPUNCT\t_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXixbTRwJ2fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_from_file(file):\n",
        "  with open(file,'r',encoding='utf-8') as f:\n",
        "    read_file=f.read().split('\\n')\n",
        "  return read_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0fUZwDlQ48z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=load_from_file(text_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-2_W2EJhmR4",
        "colab_type": "code",
        "outputId": "a873e01c-e9cb-413f-b3dd-393b5f1af138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import string\n",
        "dataset = list(filter(None, dataset))\n",
        "text = ''.join([('' if iteration.split('\\t')[2]=='PUNCT' else ' ')+iteration.split('\\t')[0] for iteration in dataset[:200]]).strip()\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начальник областного управления связи Семен Еремеевич был человек простой, приходил на работу всегда вовремя, здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом\" Муха\". В приемной его с утра ожидали посетители,- кое-кто с важными делами, а кое-кто и с такими, которые легко можно было решить в нижестоящих инстанциях, не затрудняя Семена Еремеевича. Однако стиль работы Семена Еремеевича заключался в том, чтобы принимать всех желающих и лично вникать в дело. Приемная была обставлена просто, но по-деловому. У двери стоял стол секретарши, на столе- пишущая машинка с широкой кареткой. В углу висел репродуктор и играло радио для развлечения ожидающих и еще для того, чтобы заглушать голос начальника, доносившийся из кабинета, так_как, бесспорно, среди посетителей могли находиться и случайные люди. Кабинет отличался скромностью, присущей Семену Еремеевичу. В глубине стоял широкий письменный стол с бронзовыми чернильницами и перед ним два кожаных кресла. Справа был стол для заседаний- длинный, накрытый зеленым сукном и с обеих сторон аккуратно заставленный стульями. Семен Еремеевич очень не любил, когда за этот стол кто-нибудь\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez72JAgsijVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_text (dataset):\n",
        "  clean_dataset=[]\n",
        "  for sentence in dataset:\n",
        "    if sentence.split('\\t')[0]!='.' and sentence.split('\\t')[2]!='PUNCT':\n",
        "      clean_dataset.append([sentence.split('\\t')[0].lower(),sentence.split('\\t')[2]])\n",
        "    elif sentence.split('\\t')[0]=='.':\n",
        "      clean_dataset.append([sentence.split('\\t')[0].lower(),sentence.split('\\t')[2]])\n",
        "    else:\n",
        "      continue\n",
        "  return clean_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phwj_XPyrOpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_dataset=clear_text(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5pZulejsDmk",
        "colab_type": "code",
        "outputId": "de15706f-d977-4900-9411-c5bc659b0a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(clean_dataset[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['начальник', 'NOUN'], ['областного', 'ADJ'], ['управления', 'NOUN'], ['связи', 'NOUN'], ['семен', 'NOUN'], ['еремеевич', 'NOUN'], ['был', 'VERB'], ['человек', 'NOUN'], ['простой', 'ADJ'], ['приходил', 'VERB'], ['на', 'ADP'], ['работу', 'NOUN'], ['всегда', 'ADV'], ['вовремя', 'ADV'], ['здоровался', 'VERB'], ['с', 'ADP'], ['секретаршей', 'NOUN'], ['за', 'ADP'], ['руку', 'NOUN'], ['и', 'CONJ']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpXoCZ8a6Hze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concatenate_words(dataset):\n",
        "  concat_words=[]\n",
        "  concat_labels=[]\n",
        "  sentence=[]\n",
        "  labels=[]\n",
        "  for word in dataset:\n",
        "    if word[1]!='PUNCT':\n",
        "      sentence.append(word[0])\n",
        "      labels.append(word[1])\n",
        "    else:\n",
        "      concat_words.append([word for word in sentence])\n",
        "      concat_labels.append([label for label in labels])\n",
        "      sentence.clear()\n",
        "      labels.clear()\n",
        "  return concat_words,concat_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cojUqfC0901R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text,labels_sen=concatenate_words(clean_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbVxmVRQwKSc",
        "colab_type": "code",
        "outputId": "b40c2a16-f01d-4f61-c2b1-33fd58cb0da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "clean_dataset=[line for line in clean_dataset if line!='']\n",
        "MAX_LEN_TOKEN=max(len(line[0]) for line in clean_dataset)\n",
        "NUMBER_UNIQUE_TOKEN=len(set(line[0] for line in clean_dataset if line[1]!='PUNCT'))\n",
        "MAX_LEN_SENTENCE=max(len(sentence) for sentence in text)\n",
        "print('Максимальная длина токена', MAX_LEN_TOKEN)\n",
        "print('Количество уникальных токенов' , NUMBER_UNIQUE_TOKEN)\n",
        "print('Максимальная длина предложения' , MAX_LEN_SENTENCE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Максимальная длина токена 31\n",
            "Количество уникальных токенов 104251\n",
            "Максимальная длина предложения 216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzin5II3qdmO",
        "colab_type": "code",
        "outputId": "2dd3a967-09cf-42d3-f1a5-4059e86caf3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels = ['<NOTAG>'] + sorted({token[1] for token in clean_dataset})\n",
        "label2id = {label: i+1 for i, label in enumerate(labels)}\n",
        "print('Метки частей речи' , label2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метки частей речи {'<NOTAG>': 1, 'ADJ': 2, 'ADP': 3, 'ADV': 4, 'CONJ': 5, 'DET': 6, 'H': 7, 'INTJ': 8, 'NOUN': 9, 'NUM': 10, 'PART': 11, 'PRON': 12, 'PUNCT': 13, 'VERB': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hov349dzJsYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "def build_vocab(text,pad_symbol='<PAD>'):\n",
        "  sentence=' '.join(line[0].lower() for line in text)\n",
        "  mydict = dict((j, i+1) for i, j in enumerate(set(sentence)))\n",
        "  mydict.update({pad_symbol:max(mydict.values())+1})\n",
        "  return mydict\n",
        "\n",
        "def counter(dataset,most_freq_symbols):\n",
        "  if most_freq_symbols is None:\n",
        "    most_freq_symbols=5\n",
        "  sentence=' '.join([word[0] for word in dataset])\n",
        "  return Counter(list(sentence)).most_common(most_freq_symbols)    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eht7psJXXKb",
        "colab_type": "code",
        "outputId": "dd80a128-bc12-455e-ee82-066a740a455a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('Символы словаря',build_vocab(text=clean_dataset[:10]),'\\n','Наиболее частотные символы',counter(clean_dataset[:10],most_freq_symbols=10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Символы словаря {'и': 1, 'б': 2, 'г': 3, 'п': 4, 'в': 5, 'с': 6, 'х': 7, ' ': 8, 'е': 9, 'я': 10, 'ы': 11, 'ч': 12, 'т': 13, 'й': 14, 'з': 15, 'н': 16, 'к': 17, 'а': 18, 'л': 19, 'м': 20, 'ь': 21, 'о': 22, 'р': 23, 'д': 24, 'у': 25, '<PAD>': 26} \n",
            " Наиболее частотные символы [(' ', 9), ('е', 9), ('о', 7), ('л', 6), ('и', 6), ('н', 5), ('а', 4), ('с', 4), ('р', 4), ('в', 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7pcJDs1eNIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=build_vocab(text=clean_dataset)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "A=np.zeros(shape=(len(text[:40000]),MAX_LEN_SENTENCE,MAX_LEN_TOKEN))\n",
        "B=np.zeros(shape=(len(text[:40000]),MAX_LEN_SENTENCE))\n",
        "for i in range(len(text[:40000])):\n",
        "  for j,word in enumerate(text[i]):\n",
        "    conv=[number for letter in word for symbol,number in vocab.items() if letter==symbol]\n",
        "    conv1=[number for symbol,number in label2id.items() if labels_sen[i][j]==symbol]\n",
        "    np.put(A[i,j],[k for k in range(len(word))],conv)\n",
        "    np.put(B[i],j,conv1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtugO1kJT4Rw",
        "colab_type": "code",
        "outputId": "49758846-c7a8-4c14-c056-ae55c0c9a74f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "A[1][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [63., 51., 24., 59., 16., 46.,  7., 55.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [59., 72.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [73.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.],\n",
              "       [70., 18., 51., 47.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqt8TAV3UQs2",
        "colab_type": "code",
        "outputId": "2bc8f1e0-9226-47ca-ec48-d1b7b52a8396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "B[1][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  9., 12.,  3.,  9.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGOyaw7gULCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_pad(words2id,text,pad_symbol,max_len_token,add_boundary=True):\n",
        "  mat_with_boundary=np.zeros(shape=(len(text),MAX_LEN_SENTENCE,MAX_LEN_TOKEN+1),dtype=int)\n",
        "  for i in range(len(text)):\n",
        "    for j in range(len(text[i])):\n",
        "      if add_boundary==True:\n",
        "        mat_with_boundary[i,j]=np.insert(words2id[i,j],0,pad_symbol)\n",
        "      else:\n",
        "        continue\n",
        "  return words2id if (add_boundary==False) else mat_with_boundary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-7nlU7CWXrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A=add_pad(A,text[:40000],pad_symbol=0,max_len_token=MAX_LEN_TOKEN,add_boundary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky2aAKB4_3OK",
        "colab_type": "code",
        "outputId": "ffa51dfe-e0b6-47ef-d6ca-c7b01df9936e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "A[1,:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 63, 51, 24, 59, 16, 46,  7, 55,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 59, 72,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 73,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 70, 18, 51, 47,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0,  7, 23, 24, 53, 47, 34, 24,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 63,  7, 73, 59, 18, 24, 18, 59, 34, 24,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 25,  7, 59, 50, 25, 18,  7,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 73,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0,  6, 47, 23, 46, 14, 16, 24,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1722F-J2AYcp",
        "colab_type": "code",
        "outputId": "5cf2c13d-2978-4984-c787-bbfda11d5dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "B[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  9., 12.,  3.,  9., 14.,  9., 12.,  3.,  2.,  9.,  5., 12.,\n",
              "       11.,  3.,  6.,  6.,  4.,  4., 14., 14.,  3.,  2.,  9., 11., 14.,\n",
              "        9.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s99eLc4cvIRT",
        "colab_type": "code",
        "outputId": "61587879-094a-46d4-bca8-620c6f36b236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(A, B, test_size=0.33, random_state=42)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cat=to_categorical(y_train, num_classes=len(label2id.values())+1)\n",
        "y_test_cat=to_categorical(y_test, num_classes=len(label2id.values())+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y6BDTOQDxeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class StackedConv1d(nn.Module):\n",
        "  def __init__(self,features_num,layers_n=1,kernel_size=3,conv_layer=nn.Conv1d,dropout=0.0):\n",
        "    super().__init__()\n",
        "    layers=[]\n",
        "    for _ in range(layers_n):\n",
        "      layers.append(nn.Sequential(conv_layer(features_num,features_num,kernel_size,padding=kernel_size//2),\n",
        "                                  nn.Dropout(dropout),\n",
        "                                  nn.LeakyReLU()))\n",
        "      self.layers=nn.ModuleList(layers)\n",
        "\n",
        "  # simple ResNet\n",
        "  def forward(self,x):\n",
        "    for layer in self.layers:\n",
        "      x=x+layer(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pCQhh1WVA9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SingleTokenPOSTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n",
        "        super().__init__()\n",
        "        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.backbone = StackedConv1d(embedding_size, **kwargs)\n",
        "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.out = nn.Linear(embedding_size, labels_num)\n",
        "        self.labels_num = labels_num\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n",
        "        batch_size, max_sent_len, max_token_len = tokens.shape\n",
        "        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n",
        "        \n",
        "        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n",
        "        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n",
        "        \n",
        "        features = self.backbone(char_embeddings)\n",
        "        \n",
        "        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n",
        "        \n",
        "        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n",
        "        logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n",
        "        logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CcmId44JNRo",
        "colab_type": "code",
        "outputId": "2fc75b99-3a4d-48de-d327-7e80ca69c02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "single_token_model=SingleTokenPOSTagger(len(vocab),len(label2id),embedding_size=64,layers_n=3,kernel_size=3,dropout=0.3)\n",
        "print(\"Количество параметров\", sum(np.product(t.shape) for t in single_token_model.parameters()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество параметров 43342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It4B-wBgarsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "import datetime\n",
        "import random\n",
        "import traceback\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def init_random_seed(value=0):\n",
        "    random.seed(value)\n",
        "    np.random.seed(value)\n",
        "    torch.manual_seed(value)\n",
        "    torch.cuda.manual_seed(value)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def copy_data_to_device(data, device):\n",
        "    if torch.is_tensor(data):\n",
        "        return data.to(device)\n",
        "    elif isinstance(data, (list, tuple)):\n",
        "        return [copy_data_to_device(elem, device) for elem in data]\n",
        "    raise ValueError('Недопустимый тип данных {}'.format(type(data)))\n",
        "\n",
        "\n",
        "def print_grad_stats(model):\n",
        "    mean = 0\n",
        "    std = 0\n",
        "    norm = 1e-5\n",
        "    for param in model.parameters():\n",
        "        grad = getattr(param, 'grad', None)\n",
        "        if grad is not None:\n",
        "            mean += grad.data.abs().mean()\n",
        "            std += grad.data.std()\n",
        "            norm += 1\n",
        "    mean /= norm\n",
        "    std /= norm\n",
        "    print(f'Mean grad {mean}, std {std}, n {norm}')\n",
        "\n",
        "def train_eval_loop(model, train_dataset, val_dataset, criterion,\n",
        "                    lr=1e-4, epoch_n=10, batch_size=32,\n",
        "                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n",
        "                    max_batches_per_epoch_train=10000,\n",
        "                    max_batches_per_epoch_val=1000,\n",
        "                    data_loader_ctor=DataLoader,\n",
        "                    optimizer_ctor=None,\n",
        "                    lr_scheduler_ctor=None,\n",
        "                    shuffle_train=True,\n",
        "                    dataloader_workers_n=0):\n",
        "    \"\"\"\n",
        "    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n",
        "    :param model: torch.nn.Module - обучаемая модель\n",
        "    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n",
        "    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n",
        "    :param criterion: функция потерь для настройки модели\n",
        "    :param lr: скорость обучения\n",
        "    :param epoch_n: максимальное количество эпох\n",
        "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
        "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
        "    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n",
        "        отсутствие улучшения модели, чтобы обучение продолжалось.\n",
        "    :param l2_reg_alpha: коэффициент L2-регуляризации\n",
        "    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n",
        "    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n",
        "    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n",
        "        (по умолчанию torch.utils.data.DataLoader)\n",
        "    :return: кортеж из двух элементов:\n",
        "        - среднее значение функции потерь на валидации на лучшей эпохе\n",
        "        - лучшая модель\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    device = torch.device(device)\n",
        "    model.to(device)\n",
        "\n",
        "    if optimizer_ctor is None:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n",
        "    else:\n",
        "        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n",
        "\n",
        "    if lr_scheduler_ctor is not None:\n",
        "        lr_scheduler = lr_scheduler_ctor(optimizer)\n",
        "    else:\n",
        "        lr_scheduler = None\n",
        "\n",
        "    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n",
        "                                        num_workers=dataloader_workers_n)\n",
        "    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                                      num_workers=dataloader_workers_n)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_epoch_i = 0\n",
        "    best_model = copy.deepcopy(model)\n",
        "\n",
        "    for epoch_i in range(epoch_n):\n",
        "        try:\n",
        "            epoch_start = datetime.datetime.now()\n",
        "            print('Эпоха {}'.format(epoch_i))\n",
        "\n",
        "            model.train()\n",
        "            mean_train_loss = 0\n",
        "            train_batches_n = 0\n",
        "            for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
        "                if batch_i > max_batches_per_epoch_train:\n",
        "                    break\n",
        "\n",
        "                batch_x = copy_data_to_device(batch_x, device)\n",
        "                batch_y = copy_data_to_device(batch_y, device)\n",
        "\n",
        "                pred = model(batch_x)\n",
        "                loss = criterion(pred, batch_y)\n",
        "\n",
        "                model.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                mean_train_loss += float(loss)\n",
        "                train_batches_n += 1\n",
        "\n",
        "            mean_train_loss /= train_batches_n\n",
        "            print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n",
        "                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\n",
        "            print('Среднее значение функции потерь на обучении', mean_train_loss)\n",
        "\n",
        "\n",
        "\n",
        "            model.eval()\n",
        "            mean_val_loss = 0\n",
        "            val_batches_n = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
        "                    if batch_i > max_batches_per_epoch_val:\n",
        "                        break\n",
        "\n",
        "                    batch_x = copy_data_to_device(batch_x, device)\n",
        "                    batch_y = copy_data_to_device(batch_y, device)\n",
        "\n",
        "                    pred = model(batch_x)\n",
        "                    loss = criterion(pred, batch_y)\n",
        "\n",
        "                    mean_val_loss += float(loss)\n",
        "                    val_batches_n += 1\n",
        "\n",
        "            mean_val_loss /= val_batches_n\n",
        "            print('Среднее значение функции потерь на валидации', mean_val_loss)\n",
        "\n",
        "            if mean_val_loss < best_val_loss:\n",
        "                best_epoch_i = epoch_i\n",
        "                best_val_loss = mean_val_loss\n",
        "                best_model = copy.deepcopy(model)\n",
        "                print('Новая лучшая модель!')\n",
        "            elif epoch_i - best_epoch_i > early_stopping_patience:\n",
        "                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n",
        "                    early_stopping_patience))\n",
        "                break\n",
        "\n",
        "            if lr_scheduler is not None:\n",
        "                lr_scheduler.step(mean_val_loss)\n",
        "\n",
        "            print()\n",
        "        except KeyboardInterrupt:\n",
        "            print('Досрочно остановлено пользователем')\n",
        "            break\n",
        "        except Exception as ex:\n",
        "            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n",
        "            break\n",
        "\n",
        "    return best_val_loss, best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4MemvZXd9GS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "X_train=torch.from_numpy(X_train).type(torch.LongTensor)\n",
        "y_train=torch.from_numpy(y_train).type(torch.LongTensor)\n",
        "X_test=torch.from_numpy(X_test).type(torch.LongTensor)\n",
        "y_test=torch.from_numpy(y_test).type(torch.LongTensor)\n",
        "\n",
        "train_dataset=TensorDataset(X_train,y_train)\n",
        "test_dataset=TensorDataset(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhc4eIO4SP3N",
        "colab_type": "code",
        "outputId": "d1f1a244-9dba-46bd-9651-8248ee8e5bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "(best_val_loss,\n",
        " best_single_token_model) = train_eval_loop(single_token_model,\n",
        "                                            train_dataset,\n",
        "                                            test_dataset,\n",
        "                                            F.cross_entropy,\n",
        "                                            lr=5e-3,\n",
        "                                            epoch_n=10,\n",
        "                                            batch_size=64,\n",
        "                                            device='cuda',\n",
        "                                            early_stopping_patience=5,\n",
        "                                            max_batches_per_epoch_train=500,\n",
        "                                            max_batches_per_epoch_val=100,\n",
        "                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n",
        "                                                                                                                       factor=0.5,\n",
        "                                                                                                                       verbose=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпоха 0\n",
            "Эпоха: 105 итераций, 28.84 сек\n",
            "Среднее значение функции потерь на обучении 0.20677193126508167\n",
            "Среднее значение функции потерь на валидации 0.10495220139049567\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 1\n",
            "Эпоха: 105 итераций, 28.62 сек\n",
            "Среднее значение функции потерь на обучении 0.06591090297415143\n",
            "Среднее значение функции потерь на валидации 0.07438985401621231\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 2\n",
            "Эпоха: 105 итераций, 28.57 сек\n",
            "Среднее значение функции потерь на обучении 0.057468069415716895\n",
            "Среднее значение функции потерь на валидации 0.07220508322979395\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 3\n",
            "Эпоха: 105 итераций, 28.53 сек\n",
            "Среднее значение функции потерь на обучении 0.05236339278164364\n",
            "Среднее значение функции потерь на валидации 0.06476892960759309\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 4\n",
            "Эпоха: 105 итераций, 28.53 сек\n",
            "Среднее значение функции потерь на обучении 0.05002376501049314\n",
            "Среднее значение функции потерь на валидации 0.06100103373710926\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 5\n",
            "Эпоха: 105 итераций, 28.53 сек\n",
            "Среднее значение функции потерь на обучении 0.04848521376649539\n",
            "Среднее значение функции потерь на валидации 0.05894504723927149\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 6\n",
            "Эпоха: 105 итераций, 28.56 сек\n",
            "Среднее значение функции потерь на обучении 0.04682180608312289\n",
            "Среднее значение функции потерь на валидации 0.05847257289748926\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 7\n",
            "Эпоха: 105 итераций, 28.56 сек\n",
            "Среднее значение функции потерь на обучении 0.04581149479462987\n",
            "Среднее значение функции потерь на валидации 0.05649728156053103\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 8\n",
            "Эпоха: 105 итераций, 28.53 сек\n",
            "Среднее значение функции потерь на обучении 0.045200154007900326\n",
            "Среднее значение функции потерь на валидации 0.05806671333714174\n",
            "\n",
            "Эпоха 9\n",
            "Эпоха: 105 итераций, 28.55 сек\n",
            "Среднее значение функции потерь на обучении 0.04430979575429644\n",
            "Среднее значение функции потерь на валидации 0.05686375183554796\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}